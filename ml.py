# -*- coding: utf-8 -*-
"""Untitled23.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FTz3iLl4jWamvhCuzvV2QDK8EeiwTE46
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from xgboost import XGBRegressor
from sklearn.multioutput import MultiOutputRegressor
import yfinance as yf
from datetime import datetime
from sqlalchemy import create_engine

import yfinance as yf

# Set start date and dynamically get today's date
start_dt = "2018-12-01"
end_dt = datetime.today().strftime('%Y-%m-%d')  # Gets today's date in YYYY-MM-DD format

ticker = ["DOGE-USD"]
df = yf.download(ticker, start=start_dt, end=end_dt)
df.columns = df.columns.droplevel(1)  # Remove the second level ('DOGE-USD')
for _ in range(30):
    # Prepare features and targets
    features = df[['Open', 'High', 'Low', 'Volume', 'Close']]
    target = df[['Open', 'High', 'Low', 'Volume', 'Close']]

    # Normalize the data
    scaler = MinMaxScaler()
    features_scaled = scaler.fit_transform(features)
    target_scaled = scaler.fit_transform(target)

    # Train-test split
    train_size = int(len(features_scaled) * 0.99)
    X_train, X_test = features_scaled[:train_size], features_scaled[train_size:]
    y_train, y_test = target_scaled[:train_size], target_scaled[train_size:]

    # Build and train the model
    model = MultiOutputRegressor(
        XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.99)
    )
    model.fit(X_train, y_train)

    # Predict and inverse transform
    predictions_scaled = model.predict(X_test)
    predictions = scaler.inverse_transform(predictions_scaled)
    y_test_original = scaler.inverse_transform(y_test)

    # Create a results DataFrame
    results = pd.DataFrame(predictions, columns=['Open', 'High', 'Low', 'Volume', 'Close'])
    results['Date'] = df.index[train_size:]
    results['Actual Open'] = y_test_original[:, 0]
    results['Actual High'] = y_test_original[:, 1]
    results['Actual Low'] = y_test_original[:, 2]
    results['Actual Volume'] = y_test_original[:, 3]
    results['Actual Close'] = y_test_original[:, 4]

    # Predict the next day
    last_features = features_scaled[-1].reshape(1, -1)
    next_day_prediction_scaled = model.predict(last_features)
    next_day_prediction = scaler.inverse_transform(next_day_prediction_scaled)

    # Append predicted next day to dataframe
    next_day = pd.DataFrame(next_day_prediction, columns=['Open', 'High', 'Low', 'Volume', 'Close'])
    next_day['Date'] = [df.index[-1] + pd.Timedelta(days=1)]
    next_day.set_index('Date', inplace=True)
    df = pd.concat([df, next_day])

# Display last 30 days including predictions
# print(df.tail(30))

# # Save the last 30 days (including forecast) to CSV
# df.tail(30).to_csv("forecast.csv")
# print("Last 30 days saved as 'forecast.csv'")
user = 'root'
password = 'Itsme$k23'
host = 'localhost'  # or your MySQL host
port = '3306'       # default MySQL port
database = 'dogecoinpriceforecasting'

# Create the SQLAlchemy engine
engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}:{port}/{database}')

# Select the last 30 rows (forecast)
forecast_data = df.tail(30).copy()
forecast_data.reset_index(inplace=True)  # To include 'Date' as a column

# Save to MySQL (append to table if exists)
forecast_data.to_sql(name='forecast_table', con=engine, if_exists='replace', index=False)

print("Last 30 days forecast saved to MySQL table `forecast_table`")